{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff7a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 4\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 1\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 2\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 3\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 5\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 1\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 4\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 2\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 3\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 4\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 5\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 1\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 3\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 4\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 2\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 1\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 5\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 2\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 4\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 5\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 3\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 1\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 2\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 4\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 3\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 1\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 5\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 2\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 4\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 5\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 3\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 1\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 3\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 2\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 4\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 5\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 1\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 2\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 4\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 3\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 1\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 5\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 2\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 4\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 3\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 5\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 1\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 2\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 3\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 4\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 5\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 1\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 2\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 4\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 3\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "PDF_FOLDER = \"pdfs\"\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "MAX_CHUNKS_PER_PDF = 5\n",
    "MAX_WORKERS = 8\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")  # Shared LLM instance\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "\n",
    "executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
    "\n",
    "def load_and_split_pdf(pdf_path):\n",
    "    loader = PyPDFLoader(pdf_path)\n",
    "    documents = loader.load()\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    return chunks[:MAX_CHUNKS_PER_PDF] if MAX_CHUNKS_PER_PDF else chunks\n",
    "\n",
    "def process_chunk_sync(content, filename, i):\n",
    "    try:\n",
    "        llm.invoke(content)\n",
    "        print(f\"‚úÖ {filename} | Chunk {i+1}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error on chunk {i+1} of {filename}: {e}\")\n",
    "\n",
    "async def process_pdf(filename):\n",
    "    if not filename.endswith(\".pdf\"):\n",
    "        return\n",
    "\n",
    "    pdf_path = os.path.join(PDF_FOLDER, filename)\n",
    "    try:\n",
    "        chunks = await asyncio.get_event_loop().run_in_executor(executor, load_and_split_pdf, pdf_path)\n",
    "\n",
    "        tasks = [\n",
    "            asyncio.get_event_loop().run_in_executor(\n",
    "                executor, process_chunk_sync, chunk.page_content, filename, i\n",
    "            )\n",
    "            for i, chunk in enumerate(chunks)\n",
    "        ]\n",
    "        await asyncio.gather(*tasks)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {filename}: {e}\")\n",
    "\n",
    "async def main():\n",
    "    pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.endswith(\".pdf\")]\n",
    "    tasks = [process_pdf(f) for f in pdf_files]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import nest_asyncio                 \n",
    "    nest_asyncio.apply()  # Allows nested use of asyncio.run()\n",
    "    asyncio.get_event_loop().run_until_complete(main())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ef0826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\pypdf\\generic\\_utils.py:156: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  return ByteStringObject(string)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0038092X16303383-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S0927024816300071-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024815001415-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024815003244-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215007183-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S0927024816302069-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816000313-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S0927024816301519-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 1\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 1\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 2\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 1\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 2\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 1\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 2\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 1\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 3\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 2\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 3\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 2\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 3\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 2\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 4\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 3\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 3\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 4\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 4\n",
      "‚úÖ 1-s2.0-S1876610215007420-main.pdf | Chunk 5\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 3\n",
      "‚úÖ 1-s2.0-S1876610215008206-main.pdf | Chunk 5\n",
      "‚úÖ 1-s2.0-S1876610215008851-main.pdf | Chunk 5\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 4\n",
      "‚úÖ Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable.pdf | Chunk 5\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 4\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 1\n",
      "‚úÖ Adani ELAN SHINE TOPCon Datasheet (550‚Äì575 W, N-Type Bifacial).pdf | Chunk 5\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 4\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 1\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 1\n",
      "‚úÖ Model_Based_Continuous_Improvement_of_Industrial_p.pdf | Chunk 5\n",
      "‚úÖ JinkoSolar Eagle 54HM G6 Datasheet (420‚Äì440 W, N-Type TOPCon).pdf | Chunk 5\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 1\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 2\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 1\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 2\n",
      "‚úÖ JinkoSolar Eagle 72 G6B Datasheet (570‚Äì590 W, N-Type Bifacial).pdf | Chunk 5\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 2\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 1\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 2\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 3\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 2\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 3\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 2\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 3\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 3\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 4\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 3\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 4\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 3\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 4\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 4\n",
      "‚úÖ Qcells Q.TRON BLK M-G2+ Series Datasheet (415‚Äì440 Wp, 2024).pdf | Chunk 5\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 4\n",
      "‚úÖ Rayzon TOPCon Datasheet (570‚Äì590 W, N-Type Bifacial, 2024).pdf | Chunk 5\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 4\n",
      "‚úÖ Silfab SIL-420_430 QD Datasheet (420‚Äì430 W, N-Type, 2022).pdf | Chunk 5\n",
      "‚úÖ Resistive_Power_Loss_Analysis_of_PV_Modules_Made_From_Halved_15.615.6_cm2_Silicon_PERC_Solar_Cells_With_Efficiencies_up_to_20.0.pdf | Chunk 5\n",
      "‚úÖ The_Glass-glass_Module_Using_n-type_Bifacial_Solar.pdf | Chunk 5\n",
      "‚úÖ Silfab SIL-520 XM Datasheet (520 W, N-Type Bifacial, 2024).pdf | Chunk 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Configuration\n",
    "PDF_FOLDER = \"pdfs\"\n",
    "CHUNK_SIZE = 500\n",
    "CHUNK_OVERLAP = 50\n",
    "MAX_CHUNKS_PER_PDF = 5\n",
    "MAX_WORKERS = os.cpu_count() or 8\n",
    "\n",
    "# Shared objects\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
    "executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
    "\n",
    "# Purely synchronous processing for one PDF file\n",
    "def process_pdf_sync(filename):\n",
    "    if not filename.endswith(\".pdf\"):\n",
    "        return\n",
    "\n",
    "    pdf_path = os.path.join(PDF_FOLDER, filename)\n",
    "    try:\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        documents = loader.load()\n",
    "        chunks = splitter.split_documents(documents)\n",
    "        for i, chunk in enumerate(chunks[:MAX_CHUNKS_PER_PDF]):\n",
    "            try:\n",
    "                llm.invoke(chunk.page_content)\n",
    "                print(f\"‚úÖ {filename} | Chunk {i+1}\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error on chunk {i+1} of {filename}: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {filename}: {e}\")\n",
    "\n",
    "# Async wrapper that delegates sync task to a thread\n",
    "async def main():\n",
    "    pdf_files = [f for f in os.listdir(PDF_FOLDER) if f.endswith(\".pdf\")]\n",
    "    loop = asyncio.get_running_loop()\n",
    "    tasks = [\n",
    "        loop.run_in_executor(executor, process_pdf_sync, f)\n",
    "        for f in pdf_files\n",
    "    ]\n",
    "    await asyncio.gather(*tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()  # Allows nested use of asyncio.run()\n",
    "    asyncio.get_event_loop().run_until_complete(main())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53e406aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Recursively loading .txt chunks...\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0038092X16303383-main\\chunk_009.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815001415-main\\chunk_052.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815001415-main\\chunk_059.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815001415-main\\chunk_061.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815003244-main\\chunk_055.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024816000313-main\\chunk_065.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024816300071-main\\chunk_072.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007183-main\\chunk_038.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_030.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_031.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_033.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_036.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable\\chunk_199.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: The_Glass-glass_Module_Using_n-type_Bifacial_Solar\\chunk_011.txt\n",
      "‚úÖ Loaded 1045 non-empty documents.\n",
      "üîß Creating new FAISS vectorstore...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     65\u001b[0m     documents \u001b[38;5;241m=\u001b[39m load_chunks()\n\u001b[1;32m---> 66\u001b[0m     vectorstore \u001b[38;5;241m=\u001b[39m prepare_vectorstore(documents)\n\u001b[0;32m     67\u001b[0m     qa_chain \u001b[38;5;241m=\u001b[39m create_qa_chain(vectorstore)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müß† RAG is ready. Ask anything (type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 53\u001b[0m, in \u001b[0;36mprepare_vectorstore\u001b[1;34m(documents)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m documents:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚ùå No documents to index. Check your chunks folder.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 53\u001b[0m vs \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(documents, embedder)\n\u001b[0;32m     54\u001b[0m vs\u001b[38;5;241m.\u001b[39msave_local(VECTORSTORE_PATH)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vs\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py:848\u001b[0m, in \u001b[0;36mVectorStore.from_documents\u001b[1;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ids):\n\u001b[0;32m    846\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ids\n\u001b[1;32m--> 848\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_texts(texts, embedding, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\langchain_community\\vectorstores\\faiss.py:1043\u001b[0m, in \u001b[0;36mFAISS.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_texts\u001b[39m(\n\u001b[0;32m   1018\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1024\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FAISS:\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct FAISS wrapper from raw documents.\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \n\u001b[0;32m   1027\u001b[0m \u001b[38;5;124;03m    This is a user friendly interface that:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;124;03m            faiss = FAISS.from_texts(texts, embeddings)\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embedding\u001b[38;5;241m.\u001b[39membed_documents(texts)\n\u001b[0;32m   1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__from(\n\u001b[0;32m   1045\u001b[0m         texts,\n\u001b[0;32m   1046\u001b[0m         embeddings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1051\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:214\u001b[0m, in \u001b[0;36mOllamaEmbeddings.embed_documents\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed documents using an Ollama deployed embedding model.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    213\u001b[0m instruction_pairs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_instruction\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts]\n\u001b[1;32m--> 214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(instruction_pairs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:202\u001b[0m, in \u001b[0;36mOllamaEmbeddings._embed\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_emb_response(prompt) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:202\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m--> 202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_emb_response(prompt) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m iter_]\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\langchain_community\\embeddings\\ollama.py:167\u001b[0m, in \u001b[0;36mOllamaEmbeddings._process_emb_response\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    161\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheaders \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[0;32m    164\u001b[0m }\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 167\u001b[0m     res \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m    168\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    169\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    170\u001b[0m         json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default_params},\n\u001b[0;32m    171\u001b[0m     )\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError raised by inference endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\requests\\api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[1;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \n\u001b[0;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\requests\\api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\requests\\adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[0;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[0;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[0;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    679\u001b[0m     )\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\http\\client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1378\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[0;32m   1379\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[0;32m   1380\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bootcamp\\Anaconda3\\Lib\\socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "CHUNKS_FOLDER = \"chunks\"\n",
    "VECTORSTORE_PATH = \"vectorstore\"\n",
    "\n",
    "# üîç Recursively load .txt chunks from all subfolders\n",
    "def load_chunks():\n",
    "    print(\"üìÑ Recursively loading .txt chunks...\")\n",
    "    docs = []\n",
    "    for root, _, files in os.walk(CHUNKS_FOLDER):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".txt\"):\n",
    "                path = os.path.join(root, filename)\n",
    "                try:\n",
    "                    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        content = f.read().strip()\n",
    "                except UnicodeDecodeError:\n",
    "                    try:\n",
    "                        with open(path, \"r\", encoding=\"latin-1\") as f:\n",
    "                            content = f.read().strip()\n",
    "                        print(f\"‚ö†Ô∏è Non-UTF8 file read with latin-1: {os.path.relpath(path, CHUNKS_FOLDER)}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Skipping unreadable file: {os.path.relpath(path, CHUNKS_FOLDER)} - {e}\")\n",
    "                        continue\n",
    "\n",
    "                if content:\n",
    "                    docs.append(Document(\n",
    "                        page_content=content,\n",
    "                        metadata={\"source\": os.path.relpath(path, CHUNKS_FOLDER)}\n",
    "                    ))\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Skipped empty file: {os.path.relpath(path, CHUNKS_FOLDER)}\")\n",
    "    print(f\"‚úÖ Loaded {len(docs)} non-empty documents.\")\n",
    "    return docs\n",
    "\n",
    "\n",
    "# üß† Embed and prepare vectorstore\n",
    "def prepare_vectorstore(documents):\n",
    "    embedder = OllamaEmbeddings(model=\"llama3.2:1b\")\n",
    "    \n",
    "    if os.path.exists(VECTORSTORE_PATH):\n",
    "        print(\"üìÇ Loading existing vectorstore...\")\n",
    "        return FAISS.load_local(VECTORSTORE_PATH, embedder)\n",
    "\n",
    "    print(\"üîß Creating new FAISS vectorstore...\")\n",
    "    if not documents:\n",
    "        raise ValueError(\"‚ùå No documents to index. Check your chunks folder.\")\n",
    "    vs = FAISS.from_documents(documents, embedder)\n",
    "    vs.save_local(VECTORSTORE_PATH)\n",
    "    return vs\n",
    "\n",
    "# üí¨ Create the RAG QA chain\n",
    "def create_qa_chain(vectorstore):\n",
    "    llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "# üöÄ Main loop\n",
    "if __name__ == \"__main__\":\n",
    "    documents = load_chunks()\n",
    "    vectorstore = prepare_vectorstore(documents)\n",
    "    qa_chain = create_qa_chain(vectorstore)\n",
    "\n",
    "    print(\"\\nüß† RAG is ready. Ask anything (type 'exit' to quit):\")\n",
    "    while True:\n",
    "        query = input(\"‚ùì> \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        result = qa_chain.run(query)\n",
    "        print(f\"üí¨ {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8168230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading .txt files from 'chunks/' recursively...\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0038092X16303383-main\\chunk_009.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815001415-main\\chunk_052.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815001415-main\\chunk_059.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815001415-main\\chunk_061.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024815003244-main\\chunk_055.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024816000313-main\\chunk_065.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S0927024816300071-main\\chunk_072.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007183-main\\chunk_038.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_030.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_033.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_031.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: 1-s2.0-S1876610215007420-main\\chunk_036.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: Intl J of Energy Research - 2021 - Gawusu - The dynamics of green supply chain management within the framework of renewable\\chunk_199.txt\n",
      "‚ö†Ô∏è Non-UTF8 file read with latin-1: The_Glass-glass_Module_Using_n-type_Bifacial_Solar\\chunk_011.txt\n",
      "‚úÖ Loaded 1045 documents.\n",
      "üîß Building new FAISS vectorstore...\n",
      "\n",
      "üß† RAG ready. Ask questions (type 'exit' to quit):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bootcamp\\AppData\\Local\\Temp\\ipykernel_33132\\602812379.py:76: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  answer = qa.run(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ I don't know, as this information isn't provided in the context.\n",
      "üí¨ I don't know the answer to your question about whether it's possible to prevent Al diffusion during a strong annealing step in the titanium nitride (TiN) deposition process. Can I help you with anything else?\n",
      "üí¨ I don't know the answer to what type of container or packaging the Jinko Solar product is stored in.\n",
      "üí¨ I don't know the answer to your question about what to expect in terms of electrical characteristics and packaging specifications for the Jinko Solar 36pcs/pallets, 72pcs/stack, 936pcs/40'HQ Container TiN layers.\n",
      "üí¨ I don't know when it comes to the specific details of the question regarding \"tract\" in the context of the given text. If you could provide more information or clarify what you are asking about, I would be happy to try and assist further.\n",
      "üí¨ I don't know the answer to what is being asked. The text provided does not explicitly state the question at the end of the passage. Can you please provide more context or clarify the question you are looking for? I'll do my best to assist you.\n",
      "üí¨ I don't know.\n",
      "üí¨ I don't know the specific module weight metric for the N-TYPE CELL TECHNOLOGY in kg or lbs.\n",
      "üí¨ I don't know.\n",
      "üí¨ I don't know, as I'm not aware of any specific results or conclusions drawn from the experiments mentioned in the text.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "CHUNKS_FOLDER = \"chunks\"\n",
    "VECTORSTORE_PATH = \"vectorstore\"\n",
    "\n",
    "# üßπ Load a single file\n",
    "def load_file(path):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read().strip()\n",
    "    except UnicodeDecodeError:\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=\"latin-1\") as f:\n",
    "                content = f.read().strip()\n",
    "            print(f\"‚ö†Ô∏è Non-UTF8 file read with latin-1: {os.path.relpath(path, CHUNKS_FOLDER)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Could not read file: {path} - {e}\")\n",
    "            return None\n",
    "    if not content:\n",
    "        print(f\"‚ö†Ô∏è Skipped empty file: {os.path.relpath(path, CHUNKS_FOLDER)}\")\n",
    "        return None\n",
    "    return Document(page_content=content, metadata={\"source\": os.path.relpath(path, CHUNKS_FOLDER)})\n",
    "\n",
    "# üîÑ Load all documents concurrently from chunks/\n",
    "def load_chunks():\n",
    "    print(\"üìÇ Loading .txt files from 'chunks/' recursively...\")\n",
    "    paths = [\n",
    "        os.path.join(root, file)\n",
    "        for root, _, files in os.walk(CHUNKS_FOLDER)\n",
    "        for file in files if file.endswith(\".txt\")\n",
    "    ]\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        docs = list(executor.map(load_file, paths))\n",
    "    documents = [doc for doc in docs if doc]\n",
    "    print(f\"‚úÖ Loaded {len(documents)} documents.\")\n",
    "    return documents\n",
    "\n",
    "# üß† Prepare or load FAISS vectorstore\n",
    "def prepare_vectorstore(documents):\n",
    "    embedder = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "    if os.path.exists(VECTORSTORE_PATH):\n",
    "        print(\"üì¶ Loading existing FAISS vectorstore...\")\n",
    "        return FAISS.load_local(VECTORSTORE_PATH, embedder)\n",
    "\n",
    "    print(\"üîß Building new FAISS vectorstore...\")\n",
    "    if not documents:\n",
    "        raise ValueError(\"‚ùå No documents found in chunks/.\")\n",
    "    vectorstore = FAISS.from_documents(documents, embedder)\n",
    "    vectorstore.save_local(VECTORSTORE_PATH)\n",
    "    return vectorstore\n",
    "\n",
    "# üßµ Create RAG chain\n",
    "def create_qa_chain(vectorstore):\n",
    "    llm = Ollama(model=\"llama3.2:1b\")\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    return RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)\n",
    "\n",
    "# üöÄ Main\n",
    "if __name__ == \"__main__\":\n",
    "    docs = load_chunks()\n",
    "    vectordb = prepare_vectorstore(docs)\n",
    "    qa = create_qa_chain(vectordb)\n",
    "\n",
    "    print(\"\\nüß† RAG ready. Ask questions (type 'exit' to quit):\")\n",
    "    while True:\n",
    "        query = input(\"‚ùì> \")\n",
    "        if query.lower() == \"exit\":\n",
    "            break\n",
    "        result = qa(query)\n",
    "        answer = result[\"result\"]\n",
    "        sources = result[\"source_documents\"]\n",
    "\n",
    "        print(f\"\\nüí¨ {answer}\\n\")\n",
    "        if sources:\n",
    "            print(\"üìö Sources:\")\n",
    "            for doc in sources:\n",
    "                print(f\" - {doc.metadata['source']}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No relevant sources found.\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
