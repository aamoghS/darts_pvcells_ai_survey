{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c4371",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-core langchain-community langchain-ollama pydantic pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c148c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from typing import Union\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class PVArticleData(BaseModel):\n",
    "    title: str = Field(\"N/A\")\n",
    "    last_name: str = Field(\"N/A\")\n",
    "    year: str = Field(\"N/A\")\n",
    "    doi: str = Field(\"N/A\")\n",
    "    research_focus: str = Field(\"N/A\")\n",
    "    key_findings: str = Field(\"N/A\")\n",
    "    device_type: str = Field(\"N/A\")\n",
    "    absorber_material: str = Field(\"N/A\")\n",
    "    absorber_material_term_used: str = Field(\"N/A\")\n",
    "    absorber_dopant_material: str = Field(\"N/A\")\n",
    "    absorber_dopant_material_term_used: str = Field(\"N/A\")\n",
    "    absorber_dopant_polarity: str = Field(\"N/A\")\n",
    "    absorber_dopant_polarity_term_used: str = Field(\"N/A\")\n",
    "    front_surface_morphology: str = Field(\"N/A\")\n",
    "    front_surface_morphology_term_used: str = Field(\"N/A\")\n",
    "    rear_surface_morphology: str = Field(\"N/A\")\n",
    "    rear_surface_morphology_term_used: str = Field(\"N/A\")\n",
    "    front_surface_passivation_material: str = Field(\"N/A\")\n",
    "    front_surface_passivation_material_term_used: str = Field(\"N/A\")\n",
    "    rear_surface_passivation_material: str = Field(\"N/A\")\n",
    "    rear_surface_passivation_material_term_used: str = Field(\"N/A\")\n",
    "    negative_metallization_material: str = Field(\"N/A\")\n",
    "    negative_metallization_material_term_used: str = Field(\"N/A\")\n",
    "    positive_metallization_material: str = Field(\"N/A\")\n",
    "    positive_metallization_material_term_used: str = Field(\"N/A\")\n",
    "    efficiency_percent: str = Field(\"N/A\")\n",
    "    cell_area_cm2: str = Field(\"N/A\")\n",
    "    short_circuit_current_a: str = Field(\"N/A\")\n",
    "    short_circuit_current_density_ma_cm2: str = Field(\"N/A\")\n",
    "    open_circuit_voltage_v: str = Field(\"N/A\")\n",
    "    fill_factor_percent: str = Field(\"N/A\")\n",
    "\n",
    "    @field_validator(\"*\", mode=\"before\")\n",
    "    def convert_to_string(cls, v):\n",
    "        return \"N/A\" if v is None else str(v)\n",
    "\n",
    "def clean_response_data(response_data):\n",
    "    if isinstance(response_data, list):\n",
    "        response_data = response_data[0] if response_data else {}\n",
    "    if isinstance(response_data, PVArticleData):\n",
    "        return response_data.model_dump()\n",
    "    if isinstance(response_data, str):\n",
    "        print(\"üß™ Cleaning string response...\")\n",
    "        cleaned = (\n",
    "            response_data.strip()\n",
    "            .removeprefix(\"```json\").removeprefix(\"```\")\n",
    "            .removesuffix(\"```\").strip()\n",
    "        )\n",
    "        try:\n",
    "            parsed = json.loads(cleaned)\n",
    "            return parsed[0] if isinstance(parsed, list) else parsed\n",
    "        except json.JSONDecodeError:\n",
    "            try:\n",
    "                cleaned = cleaned.replace('\\n', '').replace('\\t', '').replace(\"'\", '\"')\n",
    "                parsed = json.loads(cleaned)\n",
    "                return parsed[0] if isinstance(parsed, list) else parsed\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå JSON decode error after cleaning: {e}\")\n",
    "                return {}\n",
    "    if isinstance(response_data, dict):\n",
    "        return response_data\n",
    "    print(\"‚ö†Ô∏è Unexpected response format:\", type(response_data))\n",
    "    return {}\n",
    "\n",
    "# Initialize model and parser\n",
    "model = ChatOllama(model=\"gemma3:4b\")\n",
    "raw_parser = PydanticOutputParser(pydantic_object=PVArticleData)\n",
    "parser = OutputFixingParser.from_llm(llm=model, parser=raw_parser)\n",
    "\n",
    "# Prompt with stronger constraints\n",
    "prompt = PromptTemplate.from_template(\"\"\"\\\n",
    "You are extracting structured data from academic articles on photovoltaic cells.\n",
    "Focus ONLY on the most efficient cell mentioned in each article.\n",
    "\n",
    "Format your response as a single **valid JSON object** only ‚Äî no markdown, no commentary, no extra text.\n",
    "\n",
    "If a value is unavailable, use \"N/A\".\n",
    "\n",
    "Your output must match this schema:\n",
    "{format_instructions}\n",
    "\n",
    "ARTICLE:\n",
    "{text}\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "pdf_folder = Path(\"PV1-Rhea\")\n",
    "pdf_files = list(pdf_folder.rglob(\"*.pdf\"))\n",
    "\n",
    "def process_pdf(pdf_file):\n",
    "    print(f\"\\nüìÑ Processing {pdf_file}...\")\n",
    "    try:\n",
    "        loader = PyPDFLoader(str(pdf_file))\n",
    "        docs = loader.load()\n",
    "        full_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
    "        chunks = splitter.split_text(full_text)\n",
    "\n",
    "        for chunk in chunks:\n",
    "            try:\n",
    "                response = chain.invoke({\n",
    "                    \"text\": chunk,\n",
    "                    \"format_instructions\": parser.get_format_instructions()\n",
    "                })\n",
    "                cleaned_data = clean_response_data(response)\n",
    "                if cleaned_data:\n",
    "                    article_data = PVArticleData(**cleaned_data)\n",
    "                    print(f\"‚úÖ Successfully extracted from {pdf_file}\")\n",
    "                    return article_data.model_dump()\n",
    "            except Exception as e:\n",
    "                print(f\"‚õî Error in chunk: {e}\")\n",
    "\n",
    "        print(f\"‚ö†Ô∏è No valid data extracted from any chunk of {pdf_file}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to process {pdf_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "results = []\n",
    "max_workers = 4\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "    futures = [executor.submit(process_pdf, pdf_file) for pdf_file in pdf_files]\n",
    "    for future in as_completed(futures):\n",
    "        result = future.result()\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "if not results:\n",
    "    print(\"‚ö†Ô∏è No PDFs were successfully processed!\")\n",
    "    exit()\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "column_map = {\n",
    "    \"title\": \"Title\", \"last_name\": \"Last Name\", \"year\": \"Year\", \"doi\": \"Digital Object Identifier (DOI)\",\n",
    "    \"research_focus\": \"Research Focus\", \"key_findings\": \"Key Findings\", \"device_type\": \"Device Type\",\n",
    "    \"absorber_material\": \"Absorber Material\", \"absorber_material_term_used\": \"Absorber Material Term Used\",\n",
    "    \"absorber_dopant_material\": \"Absorber Dopant Material\", \"absorber_dopant_material_term_used\": \"Absorber Dopant Material Term Used\",\n",
    "    \"absorber_dopant_polarity\": \"Absorber Dopant Polarity\", \"absorber_dopant_polarity_term_used\": \"Absorber Dopant Polarity Term Used\",\n",
    "    \"front_surface_morphology\": \"Front Surface Morphology\", \"front_surface_morphology_term_used\": \"Front Surface Morphology Term Used\",\n",
    "    \"rear_surface_morphology\": \"Rear Surface Morphology\", \"rear_surface_morphology_term_used\": \"Rear Surface Morphology Term Used\",\n",
    "    \"front_surface_passivation_material\": \"Front Surface Passivation Material\", \"front_surface_passivation_material_term_used\": \"Front Surface Passivation Material Term Used\",\n",
    "    \"rear_surface_passivation_material\": \"Rear Surface Passivation Material\", \"rear_surface_passivation_material_term_used\": \"Rear Surface Passivation Material Term Used\",\n",
    "    \"negative_metallization_material\": \"Negative Metallization Material\", \"negative_metallization_material_term_used\": \"Negative Metallization Material Term Used\",\n",
    "    \"positive_metallization_material\": \"Positive Metallization Material\", \"positive_metallization_material_term_used\": \"Positive Metallization Material Term Used\",\n",
    "    \"efficiency_percent\": \"Efficiency (%)\", \"cell_area_cm2\": \"Cell Area (cm2)\",\n",
    "    \"short_circuit_current_a\": \"Short-Circuit Current (A)\", \"short_circuit_current_density_ma_cm2\": \"Short-Circuit Current Density (mA/cm2)\",\n",
    "    \"open_circuit_voltage_v\": \"Open-Circuit Voltage (V)\", \"fill_factor_percent\": \"Fill Factor (%)\"\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_map)\n",
    "df = df[list(column_map.values())]\n",
    "\n",
    "output_file = \"pv_extraction_results_ollama2.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\n Extracted the folder to this pdf \")\n",
    "print(f\"\\n‚úÖ Saved extracted data to {output_file} ({len(results)} records)\")\n",
    "print(f\"üìä Processing summary: {len(results)}/{len(pdf_files)} PDFs processed successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac19f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from queue import Queue\n",
    "from threading import Thread, Lock\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üì¶ Data Schema using Pydantic\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "class PVArticleData(BaseModel):\n",
    "    title: str = Field(\"N/A\")\n",
    "    last_name: str = Field(\"N/A\")\n",
    "    year: str = Field(\"N/A\")\n",
    "    doi: str = Field(\"N/A\")\n",
    "    research_focus: str = Field(\"N/A\")\n",
    "    key_findings: str = Field(\"N/A\")\n",
    "    device_type: str = Field(\"N/A\")\n",
    "    absorber_material: str = Field(\"N/A\")\n",
    "    absorber_material_term_used: str = Field(\"N/A\")\n",
    "    absorber_dopant_material: str = Field(\"N/A\")\n",
    "    absorber_dopant_material_term_used: str = Field(\"N/A\")\n",
    "    absorber_dopant_polarity: str = Field(\"N/A\")\n",
    "    absorber_dopant_polarity_term_used: str = Field(\"N/A\")\n",
    "    front_surface_morphology: str = Field(\"N/A\")\n",
    "    front_surface_morphology_term_used: str = Field(\"N/A\")\n",
    "    rear_surface_morphology: str = Field(\"N/A\")\n",
    "    rear_surface_morphology_term_used: str = Field(\"N/A\")\n",
    "    front_surface_passivation_material: str = Field(\"N/A\")\n",
    "    front_surface_passivation_material_term_used: str = Field(\"N/A\")\n",
    "    rear_surface_passivation_material: str = Field(\"N/A\")\n",
    "    rear_surface_passivation_material_term_used: str = Field(\"N/A\")\n",
    "    negative_metallization_material: str = Field(\"N/A\")\n",
    "    negative_metallization_material_term_used: str = Field(\"N/A\")\n",
    "    positive_metallization_material: str = Field(\"N/A\")\n",
    "    positive_metallization_material_term_used: str = Field(\"N/A\")\n",
    "    efficiency_percent: str = Field(\"N/A\")\n",
    "    cell_area_cm2: str = Field(\"N/A\")\n",
    "    short_circuit_current_a: str = Field(\"N/A\")\n",
    "    short_circuit_current_density_ma_cm2: str = Field(\"N/A\")\n",
    "    open_circuit_voltage_v: str = Field(\"N/A\")\n",
    "    fill_factor_percent: str = Field(\"N/A\")\n",
    "\n",
    "    @field_validator(\"*\", mode=\"before\")\n",
    "    def to_str(cls, v):\n",
    "        return \"N/A\" if v is None else str(v)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üßπ Helper: Clean LLM output\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def clean_response_data(response_data):\n",
    "    if isinstance(response_data, PVArticleData):\n",
    "        return response_data.model_dump()\n",
    "\n",
    "    if isinstance(response_data, str):\n",
    "        cleaned = response_data.strip().removeprefix(\"```json\").removeprefix(\"```\").removesuffix(\"```\").strip()\n",
    "        try:\n",
    "            return json.loads(cleaned)\n",
    "        except:\n",
    "            cleaned = cleaned.replace(\"\\n\", \"\").replace(\"\\t\", \"\").replace(\"'\", '\"')\n",
    "            try:\n",
    "                return json.loads(cleaned)\n",
    "            except:\n",
    "                return {}\n",
    "\n",
    "    if isinstance(response_data, dict):\n",
    "        return response_data\n",
    "    if isinstance(response_data, list) and response_data:\n",
    "        return response_data[0]\n",
    "\n",
    "    return {}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üß† LLM Setup\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "model = ChatOllama(model=\"gemma3:4b\")\n",
    "raw_parser = PydanticOutputParser(pydantic_object=PVArticleData)\n",
    "parser = OutputFixingParser.from_llm(llm=model, parser=raw_parser)\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"\"\"\\\n",
    "You are extracting structured data from academic articles on photovoltaic cells.\n",
    "Focus ONLY on the most efficient cell mentioned in each article.\n",
    "\n",
    "Format your response as a single **valid JSON object** only ‚Äî no markdown, no commentary, no extra text.\n",
    "If a value is unavailable, use \"N/A\".\n",
    "\n",
    "Your output must match this schema:\n",
    "{format_instructions}\n",
    "\n",
    "ARTICLE:\n",
    "{text}\n",
    "\"\"\")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üßµ Worker Thread\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def process_pdf_worker(queue: Queue, results: list, lock: Lock):\n",
    "    while True:\n",
    "        pdf_file = queue.get()\n",
    "        if pdf_file is None:\n",
    "            break\n",
    "\n",
    "        try:\n",
    "            print(f\"üìÑ Processing: {pdf_file.name}\")\n",
    "            loader = PyPDFLoader(str(pdf_file))\n",
    "            docs = loader.load()\n",
    "            full_text = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "            splitter = RecursiveCharacterTextSplitter(chunk_size=6000, chunk_overlap=200)\n",
    "            chunks = splitter.split_text(full_text)\n",
    "\n",
    "            for chunk in chunks:\n",
    "                try:\n",
    "                    response = chain.invoke({\n",
    "                        \"text\": chunk,\n",
    "                        \"format_instructions\": parser.get_format_instructions()\n",
    "                    })\n",
    "                    parsed = clean_response_data(response)\n",
    "                    if parsed:\n",
    "                        article = PVArticleData(**parsed)\n",
    "                        with lock:\n",
    "                            results.append(article.model_dump())\n",
    "                        print(f\"‚úÖ Success: {pdf_file.name}\")\n",
    "                        break\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Chunk error: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to load {pdf_file.name}: {e}\")\n",
    "        finally:\n",
    "            queue.task_done()\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üöÄ Main Execution\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def run_extraction(pdf_dir=\"PV1-Rhea\", output_csv=\"pv_extraction_results_queue.csv\", num_threads=2):\n",
    "    pdf_folder = Path(pdf_dir)\n",
    "    pdf_files = list(pdf_folder.rglob(\"*.pdf\"))\n",
    "\n",
    "    task_queue = Queue()\n",
    "    results = []\n",
    "    lock = Lock()\n",
    "\n",
    "    # Start worker threads\n",
    "    threads = []\n",
    "    for _ in range(num_threads):\n",
    "        t = Thread(target=process_pdf_worker, args=(task_queue, results, lock))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "    # Enqueue PDFs\n",
    "    for pdf_file in pdf_files:\n",
    "        task_queue.put(pdf_file)\n",
    "\n",
    "    # Wait for all tasks to finish\n",
    "    task_queue.join()\n",
    "\n",
    "    # Stop workers\n",
    "    for _ in threads:\n",
    "        task_queue.put(None)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "\n",
    "    # Save results\n",
    "    if results:\n",
    "        save_results_to_csv(results, output_csv)\n",
    "        print(f\"\\n‚úÖ Extracted {len(results)} / {len(pdf_files)} PDFs.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No valid data extracted.\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üíæ Save to CSV\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "def save_results_to_csv(results, output_path):\n",
    "    df = pd.DataFrame(results)\n",
    "\n",
    "    column_map = {\n",
    "        \"title\": \"Title\", \"last_name\": \"Last Name\", \"year\": \"Year\", \"doi\": \"Digital Object Identifier (DOI)\",\n",
    "        \"research_focus\": \"Research Focus\", \"key_findings\": \"Key Findings\", \"device_type\": \"Device Type\",\n",
    "        \"absorber_material\": \"Absorber Material\", \"absorber_material_term_used\": \"Absorber Material Term Used\",\n",
    "        \"absorber_dopant_material\": \"Absorber Dopant Material\", \"absorber_dopant_material_term_used\": \"Absorber Dopant Material Term Used\",\n",
    "        \"absorber_dopant_polarity\": \"Absorber Dopant Polarity\", \"absorber_dopant_polarity_term_used\": \"Absorber Dopant Polarity Term Used\",\n",
    "        \"front_surface_morphology\": \"Front Surface Morphology\", \"front_surface_morphology_term_used\": \"Front Surface Morphology Term Used\",\n",
    "        \"rear_surface_morphology\": \"Rear Surface Morphology\", \"rear_surface_morphology_term_used\": \"Rear Surface Morphology Term Used\",\n",
    "        \"front_surface_passivation_material\": \"Front Surface Passivation Material\", \"front_surface_passivation_material_term_used\": \"Front Surface Passivation Material Term Used\",\n",
    "        \"rear_surface_passivation_material\": \"Rear Surface Passivation Material\", \"rear_surface_passivation_material_term_used\": \"Rear Surface Passivation Material Term Used\",\n",
    "        \"negative_metallization_material\": \"Negative Metallization Material\", \"negative_metallization_material_term_used\": \"Negative Metallization Material Term Used\",\n",
    "        \"positive_metallization_material\": \"Positive Metallization Material\", \"positive_metallization_material_term_used\": \"Positive Metallization Material Term Used\",\n",
    "        \"efficiency_percent\": \"Efficiency (%)\", \"cell_area_cm2\": \"Cell Area (cm2)\",\n",
    "        \"short_circuit_current_a\": \"Short-Circuit Current (A)\", \"short_circuit_current_density_ma_cm2\": \"Short-Circuit Current Density (mA/cm2)\",\n",
    "        \"open_circuit_voltage_v\": \"Open-Circuit Voltage (V)\", \"fill_factor_percent\": \"Fill Factor (%)\"\n",
    "    }\n",
    "\n",
    "    df = df.rename(columns=column_map)\n",
    "    df = df[list(column_map.values())]\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"üìÅ Saved to {output_path}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# üèÅ Run the pipeline\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_extraction()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
